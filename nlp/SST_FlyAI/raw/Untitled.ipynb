{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "#from flyai.dataset import Dataset\n",
    "from model import Model\n",
    "from path import MODEL_PATH\n",
    "import tensorflow as tf\n",
    "import bert.modeling as modeling\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# 超参\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-e\", \"--EPOCHS\", default=1, type=int, help=\"train epochs\")\n",
    "parser.add_argument(\"-b\", \"--BATCH\", default=16, type=int, help=\"batch size\")\n",
    "args = parser.parse_args([])\n",
    "\n",
    "# 数据获取辅助类\n",
    "dataset = Dataset(epochs=args.EPOCHS, batch=args.BATCH)\n",
    "# 模型操作辅助类\n",
    "modelpp = Model(dataset)\n",
    "\n",
    "path = modelpp.get_remote_date(\"https://www.flyai.com/m/multi_cased_L-12_H-768_A-12.zip\")\n",
    "'''\n",
    "使用tensorflow实现自己的算法\n",
    "\n",
    "'''\n",
    "# 得到训练和测试的数据\n",
    "\n",
    "lr = 0.0006  # 学习率\n",
    "# 配置文件\n",
    "\n",
    "data_root = os.path.splitext(path)[0]\n",
    "bert_config_file = os.path.join(data_root, 'bert_config.json')\n",
    "bert_config = modeling.BertConfig.from_json_file(bert_config_file)\n",
    "init_checkpoint = os.path.join(data_root, 'bert_model.ckpt')\n",
    "bert_vocab_file = os.path.join(data_root, 'vocab.txt')\n",
    "# ——————————————————导入数据——————————————————————\n",
    "\n",
    "input_ids = tf.placeholder(tf.int32, shape=[None, None], name='input_ids')\n",
    "input_mask = tf.placeholder(tf.int32, shape=[None, None], name='input_masks')\n",
    "segment_ids = tf.placeholder(tf.int32, shape=[None, None], name='segment_ids')\n",
    "input_y = tf.placeholder(tf.float32, shape=[None, 1], name=\"input_y\")\n",
    "# ——————————————————定义神经网络变量——————————————————\n",
    "# 输入层、输出层权重、偏置\n",
    "\n",
    "#with tf.variable_scope('in_out',reuse=tf.AUTO_REUSE):\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([768, 1]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.constant(0.1, shape=[1, ]))\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# ——————————————————定义神经网络变量——————————————————\n",
    "# 初始化BERT\n",
    "model = modeling.BertModel(\n",
    "    config=bert_config,\n",
    "    is_training=False,\n",
    "    input_ids=input_ids,\n",
    "    input_mask=input_mask,\n",
    "    token_type_ids=segment_ids,\n",
    "    use_one_hot_embeddings=False)\n",
    "\n",
    "# 加载bert模型\n",
    "tvars = tf.trainable_variables()\n",
    "(assignment, initialized_variable_names) = modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)\n",
    "tf.train.init_from_checkpoint(init_checkpoint, assignment)\n",
    "# 获取最后一层。\n",
    "#output_layer = model.get_sequence_output()# 这个获取每个token的output 输出[batch_size, seq_length, embedding_size] 如果做seq2seq 或者ner 用这个\n",
    "output_layer_pooled = model.get_pooled_output() # 这个获取句子的output\n",
    "\n",
    "\n",
    "# ——————————————————训练模型——————————————————\n",
    "\n",
    "w_out = weights['out']\n",
    "b_out = biases['out']\n",
    "pred = tf.add(tf.matmul(output_layer_pooled, w_out), b_out, name=\"pre1\")\n",
    "pred=tf.reshape(pred,shape=[-1,1],name=\"pre\")\n",
    "\n",
    "\n",
    "# # 损失函数\n",
    "loss=tf.reduce_mean(tf.square(tf.reshape(pred, [-1]) - tf.reshape(input_y, [-1])))\n",
    "tf.summary.scalar('loss',loss)\n",
    "#\n",
    "train_op = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "with tf.Session() as sess:\n",
    "    merged = tf.summary.merge_all()  # 将图形、训练过程等数据合并在一起\n",
    "    writer = tf.summary.FileWriter('./logs', sess.graph)  # 将训练日志写入到logs文件夹下\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(dataset.get_step()):\n",
    "        x_train, y_train, x_test, y_test = dataset.next_batch(args.BATCH)\n",
    "        x_input_ids=x_train[0]\n",
    "        x_input_mask=x_train[1]\n",
    "        x_segment_ids=x_train[2]\n",
    "#        sess.run(train_op, feed_dict={input_ids: x_input_ids,input_mask: x_input_mask,segment_ids: x_segment_ids, input_y: y_train})\n",
    "        res,loss_,_= sess.run([merged,loss,train_op],feed_dict={input_ids: x_input_ids,input_mask: x_input_mask,segment_ids: x_segment_ids, input_y: y_train})\n",
    "        print('steps:{}loss:{}'.format(i,loss_))\n",
    "        writer.add_summary(res, i)  # 将日志数据写入文件\n",
    "        if i%1000==0:\n",
    "            modelpp.save_model(sess, MODEL_PATH, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
