{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-f\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from dataset import Dataset\n",
    "#try:\n",
    "#    from dataset import Dataset\n",
    "#except:\n",
    "#    from flyai.dataset import Dataset\n",
    "\n",
    "import bert.modeling as modeling\n",
    "from bert import tokenization\n",
    "from model import Model\n",
    "from path import MODEL_PATH\n",
    "# 超参\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-e\", \"--EPOCHS\", default=20, type=int, help=\"train epochs\")\n",
    "parser.add_argument(\"-b\", \"--BATCH\", default=16, type=int, help=\"batch size\")\n",
    "args = parser.parse_args([])\n",
    "\n",
    "# 数据获取辅助类\n",
    "dataset = Dataset()\n",
    "# 模型操作辅助类\n",
    "modelpp = Model(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bert.modeling.BertConfig at 0x7f0963b327f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert import BertAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert import tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from path import DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_vocab_file = os.path.join(DATA_PATH, \"model\", \"uncased_L-12_H-768_A-12\", 'vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file data/input/model/uncased_L-12_H-768_A-12/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(bert_vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['who', 'was', 'jim', 'henson']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"Who was Jim Henson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert.run_classifier import convert_single_example_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([101,\n",
       "  2040,\n",
       "  2001,\n",
       "  3958,\n",
       "  27227,\n",
       "  1029,\n",
       "  102,\n",
       "  3958,\n",
       "  27227,\n",
       "  2001,\n",
       "  1037,\n",
       "  13997,\n",
       "  11510,\n",
       "  1012,\n",
       "  102,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_single_example_simple(max_seq_length=20,tokenizer=tokenizer,text_a=\"Who was Jim Henson ?\",text_b=\"Jim Henson was a puppeteer .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/changebio/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM,BertForSequenceClassification\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenized input\n",
    "text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "\n",
    "# Mask a token that we will try to predict back with `BertForMaskedLM`\n",
    "masked_index = 8\n",
    "tokenized_text[masked_index] = '[MASK]'\n",
    "assert tokenized_text == ['[CLS]', 'who', 'was', 'jim', 'henson', '?', '[SEP]', 'jim', '[MASK]', 'was', 'a', 'puppet', '##eer', '[SEP]']\n",
    "\n",
    "# Convert token to vocabulary indices\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "# Define sentence A and B indices associated to 1st and 2nd sentences (see paper)\n",
    "segments_ids = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2040,  2001,  3958, 27227,  1029,   102,  3958,   103,  2001,\n",
       "          1037, 13997, 11510,   102]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "?BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/changebio/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "INFO:pytorch_pretrained_bert.modeling:extracting archive file /home/changebio/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpwo0zirhg\n",
      "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:pytorch_pretrained_bert.modeling:Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "INFO:pytorch_pretrained_bert.modeling:Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=2)\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/changebio/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "INFO:pytorch_pretrained_bert.modeling:extracting archive file /home/changebio/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpgng_gme3\n",
      "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:pytorch_pretrained_bert.modeling:Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "INFO:pytorch_pretrained_bert.modeling:Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a5b39d55286a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Predict hidden states features for each layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mencoded_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegments_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m# We have a hidden states for each of the 12 layers in model bert-base-uncased\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_layers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "# If you have a GPU, put everything on cuda\n",
    "tokens_tensor = tokens_tensor.to('cuda')\n",
    "segments_tensors = segments_tensors.to('cuda')\n",
    "model.to('cuda')\n",
    "\n",
    "# Predict hidden states features for each layer\n",
    "with torch.no_grad():\n",
    "    encoded_layers, _ = model(tokens_tensor, segments_tensors)\n",
    "# We have a hidden states for each of the 12 layers in model bert-base-uncased\n",
    "assert len(encoded_layers) == 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = dataset.next_batch(args.BATCH)\n",
    "x_input_ids = x_train[0]\n",
    "x_input_mask = x_train[1]\n",
    "x_segment_ids = x_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "?BertAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "?loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_pretrained_bert.optimization:t_total value of -1 results in schedule not being applied\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4690, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4785, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4030, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4726, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1654, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2517, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4269, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6581, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6490, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4570, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5563, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1525, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2573, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3967, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4833, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5050, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3555, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5206, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2180, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3024, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "optimizer = BertAdam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "loss_fn = nn.CrossEntropyLoss()  \n",
    "for i in range(args.EPOCHS):\n",
    "    x_train, y_train, x_test, y_test = dataset.next_batch(args.BATCH)\n",
    "    x_input_ids = x_train[0]\n",
    "    x_input_mask = x_train[1]\n",
    "    x_segment_ids = x_train[2]\n",
    "\n",
    "    x_input_ids=torch.from_numpy(x_input_ids).to('cuda')\n",
    "    x_input_mask=torch.from_numpy(x_input_mask).to('cuda')\n",
    "    x_segment_ids = torch.from_numpy(x_segment_ids).to('cuda')\n",
    "    y_train = torch.from_numpy(y_train).to('cuda')\n",
    "\n",
    "    outputs = model(x_input_ids,x_segment_ids,x_input_mask)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss = loss_fn(outputs, y_train)\n",
    "    loss.backward()\n",
    "    print(loss)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model(x_input_ids,x_segment_ids,x_input_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7883, 0.8513],\n",
       "        [0.7983, 0.8764],\n",
       "        [0.7920, 0.8793],\n",
       "        [0.7923, 0.8668],\n",
       "        [0.7876, 0.8553],\n",
       "        [0.7869, 0.8356],\n",
       "        [0.7892, 0.8561],\n",
       "        [0.7823, 0.8503],\n",
       "        [0.7957, 0.8578],\n",
       "        [0.7893, 0.8246],\n",
       "        [0.7733, 0.7679],\n",
       "        [0.7848, 0.8335],\n",
       "        [0.7898, 0.8627],\n",
       "        [0.7845, 0.7867],\n",
       "        [0.7998, 0.8682],\n",
       "        [0.7880, 0.8257]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model download succeeded !\n",
      "bret_path data/input/model/uncased_L-12_H-768_A-12.zip\n",
      "loss: 30.050611\n",
      "loss: 47327.93\n",
      "loss: 536.47925\n",
      "loss: 47685.582\n",
      "loss: 10079.994\n",
      "loss: 5027.6685\n",
      "loss: 26.975506\n",
      "loss: 1975.286\n",
      "loss: 254.80496\n",
      "loss: 570.1449\n",
      "loss: 1455.8423\n",
      "loss: 583.6741\n",
      "loss: 8.960073\n",
      "loss: 613.5812\n",
      "loss: 828.2617\n",
      "loss: 258.0138\n",
      "loss: 13.890854\n",
      "loss: 383.17657\n",
      "loss: 534.7079\n",
      "loss: 208.96922\n",
      "INFO:tensorflow:No assets to save.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: data/output/model/best/saved_model.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: data/output/model/best/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "path = modelpp.get_remote_date(\"https://test.flyai.com/m/uncased_L-12_H-768_A-12.zip\")\n",
    "print('bret_path', path)\n",
    "\n",
    "lr = 0.0006  # 学习率\n",
    "# 配置文件\n",
    "data_root = os.path.splitext(path)[0]\n",
    "bert_config_file = os.path.join(data_root, 'bert_config.json')\n",
    "bert_config = modeling.BertConfig.from_json_file(bert_config_file)\n",
    "init_checkpoint = os.path.join(data_root, 'bert_model.ckpt')\n",
    "bert_vocab_file = os.path.join(data_root, 'vocab.txt')\n",
    "token = tokenization.CharTokenizer(vocab_file=bert_vocab_file)\n",
    "\n",
    "input_ids = tf.placeholder(tf.int32, shape=[None, None], name='input_ids')\n",
    "input_mask = tf.placeholder(tf.int32, shape=[None, None], name='input_masks')\n",
    "segment_ids = tf.placeholder(tf.int32, shape=[None, None], name='segment_ids')\n",
    "input_y = tf.placeholder(tf.float32, shape=[None, 1], name=\"input_y\")\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([768, 1]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.constant(0.1, shape=[1, ]))\n",
    "}\n",
    "\n",
    "model = modeling.BertModel(\n",
    "    config=bert_config,\n",
    "    is_training=False,\n",
    "    input_ids=input_ids,\n",
    "    input_mask=input_mask,\n",
    "    token_type_ids=segment_ids,\n",
    "    use_one_hot_embeddings=False)\n",
    "\n",
    "tvars = tf.trainable_variables()\n",
    "(assignment, initialized_variable_names) = modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)\n",
    "tf.train.init_from_checkpoint(init_checkpoint, assignment)\n",
    "output_layer_pooled = model.get_pooled_output()  # 这个获取句子的output\n",
    "\n",
    "w_out = weights['out']\n",
    "b_out = biases['out']\n",
    "pred = tf.add(tf.matmul(output_layer_pooled, w_out), b_out, name=\"pre1\")\n",
    "pred = tf.reshape(pred, shape=[-1, 1], name=\"pre\")\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(tf.reshape(pred, [-1]) - tf.reshape(input_y, [-1])))\n",
    "#\n",
    "train_op = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(args.EPOCHS):\n",
    "        x_train, y_train, x_test, y_test = dataset.next_batch(args.BATCH)\n",
    "        x_input_ids = x_train[0]\n",
    "        x_input_mask = x_train[1]\n",
    "        x_segment_ids = x_train[2]\n",
    "        loss_, _ = sess.run([loss, train_op],\n",
    "                            feed_dict={input_ids: x_input_ids, input_mask: x_input_mask, segment_ids: x_segment_ids,\n",
    "                                       input_y: y_train})\n",
    "        print('loss:', loss_)\n",
    "\n",
    "    modelpp.save_model(sess, MODEL_PATH, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 101, 1940,  100, ...,    0,    0,    0],\n",
       "        [ 101, 1855,  100, ...,    0,    0,    0],\n",
       "        [ 101, 1855,  100, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 1855,  100, ...,    0,    0,    0],\n",
       "        [ 101, 1855, 1916, ...,    0,    0,    0],\n",
       "        [ 101,  100,  100, ...,    0,    0,    0]]),\n",
       " array([[1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_all_processor_data()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(100, 256), (100, 256), (100, 256)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.shape for i in dataset.get_all_processor_data()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'ATEC', 'type': 'csv', 'config': {'train_url': 'https://dataset.flyai.com/dataset/ATEC/dev.zip', 'test_url': 'https://dataset.flyai.com/dataset/ATEC/dev.zip'}}\n",
      "[200.0, 26183.07, 16734.344824600794, 153.0, 11378.25, 24999.0, 36142.75, 62669.0]\n",
      "[200.0, 0.11, 0.3136749269530403, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "不要冻结我的花呗                                   2\n",
      "另一个支付宝花呗关了，新的支付宝能开通花呗吗                     2\n",
      "临时花呗额度参加分期吗                                2\n",
      "收钱码能向用户收花呗付款吗                              2\n",
      "花呗额度可以转到银行卡里面吗                             2\n",
      "今天花呗付款，没有鼓励金                               2\n",
      "借呗还有多少                                     2\n",
      "花呗能寄快递吗                                    2\n",
      "我开通了，，信用卡和花呗的，什么到现在怎么还没有通过，申请到现在怎么还没有通过    2\n",
      "花呗的钱想提前还上怎么弄                               2\n",
      "Name: texta, dtype: int64\n",
      "负的额度还可以用花呗支付吗    2\n",
      "没有找到花呗怎么办        2\n",
      "花呗分期付款，只能用一次吗    2\n",
      "用了花呗的钱怎还呀        2\n",
      "花呗付款也没有奖励金       2\n",
      "借呗切换网商贷          2\n",
      "花呗可以关了自动还款吗      2\n",
      "开通花呗不用有什么费用      2\n",
      "我说花呗里么么有钱        2\n",
      "我还要还几个月的花呗款      2\n",
      "Name: textb, dtype: int64\n",
      "0    178\n",
      "1     22\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>texta</th>\n",
       "      <th>textb</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11367</td>\n",
       "      <td>花呗额度可以转到银行卡里面吗</td>\n",
       "      <td>账户余额里的钱可以还给花呗吗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33911</td>\n",
       "      <td>我只有花呗里有钱</td>\n",
       "      <td>我说花呗里么么有钱</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10747</td>\n",
       "      <td>我用花呗直接付款可以分期吗</td>\n",
       "      <td>我要花呗分期还款有利息吗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>717</td>\n",
       "      <td>花呗需要手机验证吗</td>\n",
       "      <td>***的花呗要验证码嘛</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19226</td>\n",
       "      <td>要还花呗，可是退款的钱还没退回花呗，如果我还了花呗退回的钱去哪儿了</td>\n",
       "      <td>他这个款又退回到花呗了，我这个钱已经还了呀，现在是什么情况，这钱到底去哪里了</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>62669</td>\n",
       "      <td>蚂蚁花呗只能***至***号选择分期付款吗</td>\n",
       "      <td>花呗分期付款，只能用一次吗</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22129</td>\n",
       "      <td>当月***号当天用的花呗，还款日是不是下月***号前了</td>\n",
       "      <td>今天是花呗还款日，如果今天购买是不是需要今天还款</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>34394</td>\n",
       "      <td>蚂蚁借呗里边就是借出来的钱，就是我在余额宝里有钱，它会自动扣除吗，就是每个月还的时候</td>\n",
       "      <td>蚂蚁借呗借的钱明天就到还款日了，可现在转不钱进余额宝，蚂蚁借呗会自动从储蓄卡扣吗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2238</td>\n",
       "      <td>我那收钱码不支持花呗付款吗</td>\n",
       "      <td>为什么花呗不支持支付</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2191</td>\n",
       "      <td>花呗自动帮我买了</td>\n",
       "      <td>花呗可以关了自动还款吗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>47648</td>\n",
       "      <td>借呗还有多少</td>\n",
       "      <td>他就说蚂蚁借呗， ***万多</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>51262</td>\n",
       "      <td>花呗是货到付款</td>\n",
       "      <td>用花呗付的 然后是货到付款</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4227</td>\n",
       "      <td>花呗的临时额度，可以分期还吗</td>\n",
       "      <td>花呗临时额度能分期付款吗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1384</td>\n",
       "      <td>收钱码能向用户收花呗付款吗</td>\n",
       "      <td>支付收款码和蚂蚁花呗收款码是一个码吗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>26020</td>\n",
       "      <td>什么时候可以分期换花呗</td>\n",
       "      <td>花呗可以分期还吗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>35573</td>\n",
       "      <td>支付宝pc端怎么找不到花呗</td>\n",
       "      <td>没有找到花呗怎么办</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>30508</td>\n",
       "      <td>使用花呗收款吗钱会到哪里</td>\n",
       "      <td>收钱码能直接花呗收款吗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>33519</td>\n",
       "      <td>花呗显示关联另一账户</td>\n",
       "      <td>关联账号花呗额度是不是一样</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>22189</td>\n",
       "      <td>今天用的花呗 什么时候还钱</td>\n",
       "      <td>***月***号用的花呗，什么时候还</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>23863</td>\n",
       "      <td>花呗逾期还最低还款还能用吗</td>\n",
       "      <td>我把逾期还完 花呗还能用么</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>57883</td>\n",
       "      <td>选择的商品支持花呗分期，我为什么不能付</td>\n",
       "      <td>商品为啥不支持花呗分期</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7902</td>\n",
       "      <td>支付宝付款可以花呗吗</td>\n",
       "      <td>蚂蚁花呗可以在实体店付款吗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>19994</td>\n",
       "      <td>我***月份还了多少花呗</td>\n",
       "      <td>怎么还清花呗还多少</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>16690</td>\n",
       "      <td>今天花呗付款，没有鼓励金</td>\n",
       "      <td>花呗付款也没有奖励金</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20722</td>\n",
       "      <td>还款日过了，为什么花呗不能用</td>\n",
       "      <td>花呗逾期怎么不能还款</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>18215</td>\n",
       "      <td>商家退到花呗，我也早就还过款了，商家退的钱</td>\n",
       "      <td>我用花呗买了东西，有退款，但是我把账单还清了，退款到哪里</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>32830</td>\n",
       "      <td>借呗活跃度是什么意思</td>\n",
       "      <td>为什么借呗是招联金融</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>33074</td>\n",
       "      <td>花呗不用利息吧</td>\n",
       "      <td>开通花呗不用有什么费用</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>52848</td>\n",
       "      <td>花呗能寄快递吗</td>\n",
       "      <td>花呗走的是什么快递</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9370</td>\n",
       "      <td>花呗分期申请发票</td>\n",
       "      <td>花呗服务费如何申请发票</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>16046</td>\n",
       "      <td>蚂蚁花呗分期中还能在分期吗</td>\n",
       "      <td>我要还花呗的分期</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>24504</td>\n",
       "      <td>我十一月十号不是还清蚂蚁借呗的款吗</td>\n",
       "      <td>借呗借钱了 每个月都还款方式是一样的吗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>29207</td>\n",
       "      <td>花呗可以扫描商家支付宝二维码付款吗</td>\n",
       "      <td>向商家支付花呗一次可以支付多少钱</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>54330</td>\n",
       "      <td>我想分期买个笔记本电脑，但是花呗额度不足怎么办</td>\n",
       "      <td>买个电脑花呗额度不够怎么办</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>153</td>\n",
       "      <td>我不想用不用的用花呗的</td>\n",
       "      <td>就是我这个支付宝不想用花呗，想用另一个支付开通花呗为什么不行</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>16935</td>\n",
       "      <td>花呗的钱想提前还上怎么弄</td>\n",
       "      <td>花呗未出账的，可以提前还</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>39323</td>\n",
       "      <td>我现在还多少钱可以恢复使用花呗</td>\n",
       "      <td>花呗逾期了还款了还可以继续使用吗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1155</td>\n",
       "      <td>蚂蚁花呗怎么看还款日期</td>\n",
       "      <td>花呗怎么看未还账单</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>49254</td>\n",
       "      <td>不要冻结我的花呗</td>\n",
       "      <td>为什么我的花呗账户冻结了</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>6551</td>\n",
       "      <td>花呗还最低，影响个人信用吗</td>\n",
       "      <td>花呗十号还钱有影响吗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>12896</td>\n",
       "      <td>蚂蚁借呗借***个月可以提前还款吗</td>\n",
       "      <td>蚂蚁借呗为什么单笔还款不能提前还</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>47825</td>\n",
       "      <td>在哪兑换花呗分期卷</td>\n",
       "      <td>现在还有花呗免息卷 可以兑换吗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>8888</td>\n",
       "      <td>蚂蚁借呗未还清还可以再借么</td>\n",
       "      <td>蚂蚁借呗在没有全部还款之前，可以再次借吗</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>11238</td>\n",
       "      <td>在花呗买东西在哪查看物流</td>\n",
       "      <td>怎么看花呗使用在哪</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>27100</td>\n",
       "      <td>我用了花呗里的钱咋还款，银行卡可不可以扣</td>\n",
       "      <td>我想用花呗付款，怎么不行响</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>7578</td>\n",
       "      <td>花呗开开通不了</td>\n",
       "      <td>怎么我不能开通花呗收款</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>20167</td>\n",
       "      <td>怎么显示不了借呗金额了</td>\n",
       "      <td>为什么我进不了蚂蚁借呗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>10351</td>\n",
       "      <td>花呗账单分期怎么看到是买什么么</td>\n",
       "      <td>花呗分期是怎么分</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>5116</td>\n",
       "      <td>开通过花呗账户之后关闭了如何再次开通</td>\n",
       "      <td>花呗另一个账号已经关闭了 新账号怎么开通</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>47197</td>\n",
       "      <td>另一个支付宝花呗关了，新的支付宝能开通花呗吗</td>\n",
       "      <td>以前的号码开通了，现在这个号码不能开通花呗了嘛</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>29793</td>\n",
       "      <td>我是这个月***日借呗***万，分***个月还</td>\n",
       "      <td>借呗分期次月还款还是当月</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>55893</td>\n",
       "      <td>借呗额度用完可以调整额度吗</td>\n",
       "      <td>借呗额度可以手动调整嘛</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>27150</td>\n",
       "      <td>借呗什么时候能恢复</td>\n",
       "      <td>借呗额度设置什么还没恢复</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>37312</td>\n",
       "      <td>如何分期还花呗的临时额度</td>\n",
       "      <td>花呗临时额度分期还款怎么算</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>31559</td>\n",
       "      <td>花呗手机号不是我得，也有可能是我以前的</td>\n",
       "      <td>我想蚂蚁借呗，可是我收不到校验码怎么办？之前手机号不用了</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>297</td>\n",
       "      <td>花呗可以跨店使用吗</td>\n",
       "      <td>花呗不用费用</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>25494</td>\n",
       "      <td>密付付款方可以用花呗吗</td>\n",
       "      <td>密付能用花呗扣款么</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>32734</td>\n",
       "      <td>我开通了，，信用卡和花呗的，什么到现在怎么还没有通过，申请到现在怎么还没有通过</td>\n",
       "      <td>申请开通花呗信用卡收钱的链接在那里</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>7583</td>\n",
       "      <td>我的借呗怎么没放款</td>\n",
       "      <td>咋个我的借呗没看见了么</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>29401</td>\n",
       "      <td>那怎么样使用花呗</td>\n",
       "      <td>用了花呗的钱怎还呀</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                       texta  \\\n",
       "0   11367                              花呗额度可以转到银行卡里面吗   \n",
       "1   33911                                    我只有花呗里有钱   \n",
       "2   10747                               我用花呗直接付款可以分期吗   \n",
       "3     717                                   花呗需要手机验证吗   \n",
       "4   19226           要还花呗，可是退款的钱还没退回花呗，如果我还了花呗退回的钱去哪儿了   \n",
       "5   62669                       蚂蚁花呗只能***至***号选择分期付款吗   \n",
       "6   22129                 当月***号当天用的花呗，还款日是不是下月***号前了   \n",
       "7   34394  蚂蚁借呗里边就是借出来的钱，就是我在余额宝里有钱，它会自动扣除吗，就是每个月还的时候   \n",
       "8    2238                               我那收钱码不支持花呗付款吗   \n",
       "9    2191                                    花呗自动帮我买了   \n",
       "10  47648                                      借呗还有多少   \n",
       "11  51262                                     花呗是货到付款   \n",
       "12   4227                              花呗的临时额度，可以分期还吗   \n",
       "13   1384                               收钱码能向用户收花呗付款吗   \n",
       "14  26020                                 什么时候可以分期换花呗   \n",
       "15  35573                               支付宝pc端怎么找不到花呗   \n",
       "16  30508                                使用花呗收款吗钱会到哪里   \n",
       "17  33519                                  花呗显示关联另一账户   \n",
       "18  22189                               今天用的花呗 什么时候还钱   \n",
       "19  23863                               花呗逾期还最低还款还能用吗   \n",
       "20  57883                         选择的商品支持花呗分期，我为什么不能付   \n",
       "21   7902                                  支付宝付款可以花呗吗   \n",
       "22  19994                                我***月份还了多少花呗   \n",
       "23  16690                                今天花呗付款，没有鼓励金   \n",
       "24  20722                              还款日过了，为什么花呗不能用   \n",
       "25  18215                       商家退到花呗，我也早就还过款了，商家退的钱   \n",
       "26  32830                                  借呗活跃度是什么意思   \n",
       "27  33074                                     花呗不用利息吧   \n",
       "28  52848                                     花呗能寄快递吗   \n",
       "29   9370                                    花呗分期申请发票   \n",
       "..    ...                                         ...   \n",
       "70  16046                               蚂蚁花呗分期中还能在分期吗   \n",
       "71  24504                           我十一月十号不是还清蚂蚁借呗的款吗   \n",
       "72  29207                           花呗可以扫描商家支付宝二维码付款吗   \n",
       "73  54330                     我想分期买个笔记本电脑，但是花呗额度不足怎么办   \n",
       "74    153                                 我不想用不用的用花呗的   \n",
       "75  16935                                花呗的钱想提前还上怎么弄   \n",
       "76  39323                             我现在还多少钱可以恢复使用花呗   \n",
       "77   1155                                 蚂蚁花呗怎么看还款日期   \n",
       "78  49254                                    不要冻结我的花呗   \n",
       "79   6551                               花呗还最低，影响个人信用吗   \n",
       "80  12896                           蚂蚁借呗借***个月可以提前还款吗   \n",
       "81  47825                                   在哪兑换花呗分期卷   \n",
       "82   8888                               蚂蚁借呗未还清还可以再借么   \n",
       "83  11238                                在花呗买东西在哪查看物流   \n",
       "84  27100                        我用了花呗里的钱咋还款，银行卡可不可以扣   \n",
       "85   7578                                     花呗开开通不了   \n",
       "86  20167                                 怎么显示不了借呗金额了   \n",
       "87  10351                             花呗账单分期怎么看到是买什么么   \n",
       "88   5116                          开通过花呗账户之后关闭了如何再次开通   \n",
       "89  47197                      另一个支付宝花呗关了，新的支付宝能开通花呗吗   \n",
       "90  29793                     我是这个月***日借呗***万，分***个月还   \n",
       "91  55893                               借呗额度用完可以调整额度吗   \n",
       "92  27150                                   借呗什么时候能恢复   \n",
       "93  37312                                如何分期还花呗的临时额度   \n",
       "94  31559                         花呗手机号不是我得，也有可能是我以前的   \n",
       "95    297                                   花呗可以跨店使用吗   \n",
       "96  25494                                 密付付款方可以用花呗吗   \n",
       "97  32734     我开通了，，信用卡和花呗的，什么到现在怎么还没有通过，申请到现在怎么还没有通过   \n",
       "98   7583                                   我的借呗怎么没放款   \n",
       "99  29401                                    那怎么样使用花呗   \n",
       "\n",
       "                                       textb  label  \n",
       "0                             账户余额里的钱可以还给花呗吗      0  \n",
       "1                                  我说花呗里么么有钱      0  \n",
       "2                               我要花呗分期还款有利息吗      0  \n",
       "3                                ***的花呗要验证码嘛      0  \n",
       "4     他这个款又退回到花呗了，我这个钱已经还了呀，现在是什么情况，这钱到底去哪里了      0  \n",
       "5                              花呗分期付款，只能用一次吗      1  \n",
       "6                   今天是花呗还款日，如果今天购买是不是需要今天还款      0  \n",
       "7   蚂蚁借呗借的钱明天就到还款日了，可现在转不钱进余额宝，蚂蚁借呗会自动从储蓄卡扣吗      0  \n",
       "8                                 为什么花呗不支持支付      0  \n",
       "9                                花呗可以关了自动还款吗      0  \n",
       "10                            他就说蚂蚁借呗， ***万多      1  \n",
       "11                             用花呗付的 然后是货到付款      1  \n",
       "12                              花呗临时额度能分期付款吗      0  \n",
       "13                        支付收款码和蚂蚁花呗收款码是一个码吗      0  \n",
       "14                                  花呗可以分期还吗      0  \n",
       "15                                 没有找到花呗怎么办      0  \n",
       "16                               收钱码能直接花呗收款吗      0  \n",
       "17                             关联账号花呗额度是不是一样      0  \n",
       "18                        ***月***号用的花呗，什么时候还      1  \n",
       "19                             我把逾期还完 花呗还能用么      0  \n",
       "20                               商品为啥不支持花呗分期      0  \n",
       "21                             蚂蚁花呗可以在实体店付款吗      0  \n",
       "22                                 怎么还清花呗还多少      0  \n",
       "23                                花呗付款也没有奖励金      1  \n",
       "24                                花呗逾期怎么不能还款      0  \n",
       "25              我用花呗买了东西，有退款，但是我把账单还清了，退款到哪里      0  \n",
       "26                                为什么借呗是招联金融      0  \n",
       "27                               开通花呗不用有什么费用      0  \n",
       "28                                 花呗走的是什么快递      0  \n",
       "29                               花呗服务费如何申请发票      0  \n",
       "..                                       ...    ...  \n",
       "70                                  我要还花呗的分期      0  \n",
       "71                       借呗借钱了 每个月都还款方式是一样的吗      0  \n",
       "72                          向商家支付花呗一次可以支付多少钱      0  \n",
       "73                             买个电脑花呗额度不够怎么办      0  \n",
       "74            就是我这个支付宝不想用花呗，想用另一个支付开通花呗为什么不行      0  \n",
       "75                              花呗未出账的，可以提前还      0  \n",
       "76                          花呗逾期了还款了还可以继续使用吗      0  \n",
       "77                                 花呗怎么看未还账单      0  \n",
       "78                              为什么我的花呗账户冻结了      0  \n",
       "79                                花呗十号还钱有影响吗      0  \n",
       "80                          蚂蚁借呗为什么单笔还款不能提前还      0  \n",
       "81                           现在还有花呗免息卷 可以兑换吗      0  \n",
       "82                      蚂蚁借呗在没有全部还款之前，可以再次借吗      1  \n",
       "83                                 怎么看花呗使用在哪      0  \n",
       "84                             我想用花呗付款，怎么不行响      0  \n",
       "85                               怎么我不能开通花呗收款      0  \n",
       "86                               为什么我进不了蚂蚁借呗      0  \n",
       "87                                  花呗分期是怎么分      0  \n",
       "88                      花呗另一个账号已经关闭了 新账号怎么开通      0  \n",
       "89                   以前的号码开通了，现在这个号码不能开通花呗了嘛      0  \n",
       "90                              借呗分期次月还款还是当月      0  \n",
       "91                               借呗额度可以手动调整嘛      1  \n",
       "92                              借呗额度设置什么还没恢复      0  \n",
       "93                             花呗临时额度分期还款怎么算      0  \n",
       "94              我想蚂蚁借呗，可是我收不到校验码怎么办？之前手机号不用了      0  \n",
       "95                                    花呗不用费用      0  \n",
       "96                                 密付能用花呗扣款么      0  \n",
       "97                         申请开通花呗信用卡收钱的链接在那里      0  \n",
       "98                               咋个我的借呗没看见了么      0  \n",
       "99                                 用了花呗的钱怎还呀      0  \n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lstm.processor import load_data\n",
    "\n",
    "trn,val = load_data()\n",
    "\n",
    "trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.496 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "x_ids = [list(jieba.cut(str(trn.iloc[i,1]))) for i in range(len(trn))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ids = [list(jieba.cut(str(trn.iloc[i,2]))) for i in range(len(trn))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlen_95 = int(np.percentile([len(o) for o in x_ids], 99))\n",
    "ylen_95 = int(np.percentile([len(o) for o in y_ids], 99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 28)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlen_95,ylen_95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1556814709667682"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(66988)/np.log(14993)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from create_dict import load_dict\n",
    "\n",
    "def load_dict(file=None):\n",
    "    char_dict_re = dict()\n",
    "    if file==None:\n",
    "        dict_path = os.path.join(DATA_PATH, 'word.dict')\n",
    "    else:\n",
    "        dict_path = os.path.join(DATA_PATH, file)\n",
    "    with open(dict_path, encoding='utf-8') as fin:\n",
    "        char_dict = json.load(fin)\n",
    "    char_dict[\"_bos_\"] = 0\n",
    "    char_dict[\"_pad_\"] = 1\n",
    "    char_dict[\"_eos_\"] = 2\n",
    "    char_dict[\"_unk_\"] = 3\n",
    "    for k, v in char_dict.items():\n",
    "        char_dict_re[v] = k\n",
    "    return char_dict, char_dict_re\n",
    "\n",
    "stoi_dict,itos_dict  = load_dict(file=\"words.dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([[ 101, 1940,  100, ...,    0,    0,    0],\n",
       "         [ 101, 1855,  100, ...,    0,    0,    0],\n",
       "         [ 101, 1855,  100, ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [ 101, 1855,  100, ...,    0,    0,    0],\n",
       "         [ 101, 1855, 1916, ...,    0,    0,    0],\n",
       "         [ 101,  100,  100, ...,    0,    0,    0]]),\n",
       "  array([[1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0]]),\n",
       "  array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]])],\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]),\n",
       " [array([[ 101, 1940,  100, ...,    0,    0,    0],\n",
       "         [ 101, 1855,  100, ...,    0,    0,    0],\n",
       "         [ 101, 1855,  100, ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [ 101, 1855,  100, ...,    0,    0,    0],\n",
       "         [ 101, 1855, 1916, ...,    0,    0,    0],\n",
       "         [ 101,  100,  100, ...,    0,    0,    0]]),\n",
       "  array([[1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0]]),\n",
       "  array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]])],\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_all_processor_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from path import DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_path = os.path.join(DATA_PATH, 'embedding.json')\n",
    "with open(embedding_path, encoding='utf-8') as f:\n",
    "    vocab = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab['能减'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e9b11dcc774d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'load_data'"
     ]
    }
   ],
   "source": [
    "from processor import load_data\n",
    "trn,val = load_data()\n",
    "trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
