{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from flyai.dataset import Dataset\n",
    "from torch.optim import Adam\n",
    "\n",
    "from model import Model\n",
    "from net import Net\n",
    "from path import MODEL_PATH\n",
    "\n",
    "# 超参\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-e\", \"--EPOCHS\", default=10, type=int, help=\"train epochs\")\n",
    "parser.add_argument(\"-b\", \"--BATCH\", default=16, type=int, help=\"batch size\")\n",
    "args = parser.parse_args([])\n",
    "\n",
    "clip = 5\n",
    "\n",
    "# 判断gpu是否可用\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "device = torch.device(device)\n",
    "\n",
    "\n",
    "def eval(model, x_test, y_test):\n",
    "    network.eval()\n",
    "    total_acc = 0.0\n",
    "    data_len = len(x_test[0])\n",
    "    x1, x2 = x_test\n",
    "    x1 = torch.from_numpy(x1)\n",
    "    x2 = torch.from_numpy(x2)\n",
    "    x1 = x1.float().to(device)\n",
    "    x2 = x2.float().to(device)\n",
    "    y_test = torch.from_numpy(y_test)\n",
    "    y_test = y_test.to(device)\n",
    "    batch_eval = model.batch_iter(x1, x2, y_test)\n",
    "\n",
    "    for x_batch1, x_batch2, y_batch in batch_eval:\n",
    "        outputs = network(x_batch1, x_batch2)\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        correct = (prediction == y_batch).sum().item()\n",
    "        total_acc += correct\n",
    "    return total_acc / data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据获取辅助类\n",
    "data = Dataset()\n",
    "network = Net().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = Adam(network.parameters(), lr=0.001, weight_decay=1e-4)  # 定义优化器，选用AdamOptimizer\n",
    "\n",
    "model = Model(data)\n",
    "iteration = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.625\n",
      "step 0, best accuracy 0.625\n",
      "0/10\n",
      "0.71875\n",
      "step 1, best accuracy 0.71875\n",
      "1/10\n",
      "0.71875\n",
      "2/10\n",
      "0.46875\n",
      "3/10\n",
      "0.625\n",
      "4/10\n",
      "0.71875\n",
      "5/10\n",
      "0.71875\n",
      "6/10\n",
      "0.46875\n",
      "7/10\n",
      "0.625\n",
      "8/10\n",
      "0.71875\n",
      "9/10\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = 0\n",
    "# 得到训练和测试的数据\n",
    "for epoch in range(args.EPOCHS):\n",
    "    network.train()\n",
    "\n",
    "    # 得到训练和测试的数据\n",
    "    x_train, y_train, x_test, y_test = data.next_batch(args.BATCH)  # 读取数据\n",
    "\n",
    "    batch_len = y_train.shape[0]\n",
    "    x1, x2 = x_train\n",
    "    x1 = torch.from_numpy(x1)\n",
    "    x2 = torch.from_numpy(x2)\n",
    "    x1 = x1.float().to(device)\n",
    "    x2 = x2.float().to(device)\n",
    "    y_train = torch.from_numpy(y_train)\n",
    "    y_train = y_train.to(device)\n",
    "\n",
    "    outputs = network(x1, x2)\n",
    "    _, prediction = torch.max(outputs.data, 1)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = outputs.float()\n",
    "    # calculate the loss according to labels\n",
    "    loss = loss_fn(outputs, y_train)\n",
    "\n",
    "    # backward transmit loss\n",
    "    loss.backward()\n",
    "\n",
    "    # adjust parameters using Adam\n",
    "    optimizer.step()\n",
    "\n",
    "    # 若测试准确率高于当前最高准确率，则保存模型\n",
    "    train_accuracy = eval(model, x_test, y_test)\n",
    "    print(train_accuracy)\n",
    "    if train_accuracy > best_accuracy:\n",
    "        best_accuracy = train_accuracy\n",
    "        model.save_model(network, MODEL_PATH, overwrite=True)\n",
    "        print(\"step %d, best accuracy %g\" % (epoch, best_accuracy))\n",
    "\n",
    "    print(str(epoch) + \"/\" + str(args.EPOCHS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import codecs\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from flyai.processor.base import Base\n",
    "\n",
    "from path import DATA_PATH  # 导入输入数据的地址\n",
    "\n",
    "#sys.stdout = codecs.getwriter(\"utf-8\")(sys.stdout.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data.db.source.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    " embedding_path = os.path.join(DATA_PATH, 'embedding.json')\n",
    "with open(embedding_path, encoding='utf-8') as f:\n",
    "    vocab = json.loads(f.read())\n",
    "max_sts_len = 10\n",
    "embedding_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=vocab.get('path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.20893999934196472,\n",
       " 0.22754999995231628,\n",
       " 0.17449000477790833,\n",
       " 0.34053999185562134,\n",
       " 0.9351699948310852]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words2vec(words,vocab,embedding_len,max_sts_len):\n",
    "    words = str(words)\n",
    "    words = re.sub(\"[\\s+\\.\\!\\/_,$%^*()+-?\\\"\\']+|[+——！，。；？、~@#￥%……&*（）]+\", \" \", words)\n",
    "    words = words.strip().split(' ')\n",
    "    \n",
    "    vecs = []\n",
    "    for word in words:\n",
    "        embedding_vector = vocab.get(word)\n",
    "        if embedding_vector is not None and len(embedding_vector) == embedding_len:\n",
    "                vecs.append(embedding_vector)\n",
    "    if len(vecs) >= max_sts_len:\n",
    "        vecs = vecs[:max_sts_len]\n",
    "    else:\n",
    "        for i in range(len(vecs), max_sts_len):\n",
    "            vecs.append([0 for j in range(embedding_len)])\n",
    "    vecs = np.stack(vecs)\n",
    "    return vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=words2vec(a.iloc[0][0],vocab,100,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 100)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NaN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-fa364c978202>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNaN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'NaN' is not defined"
     ]
    }
   ],
   "source": [
    "[1,2,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import isnan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "num_dims = 100\n",
    "\n",
    "\n",
    "class LSTMNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.LSTM_stack = nn.LSTM(num_dims, 64, num_layers=2, batch_first=True)\n",
    "        for name, param in self.LSTM_stack.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight' in name:\n",
    "                nn.init.xavier_normal_(param)\n",
    "\n",
    "        self.relu1 = nn.ReLU(True)\n",
    "        self.fc1 = nn.Linear(10 * 64 * 2, 128)  ##  (max sentence length * hidden layer, 512)\n",
    "        self.relu2 = nn.ReLU(True)\n",
    "        self.dp = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "        self.bn = nn.BatchNorm1d()\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1, _ = self.LSTM_stack(x1.float())  # (batch, sentence_len, hidden_units)\n",
    "        x2, _ = self.LSTM_stack(x2.float())\n",
    "        x = torch.cat((x1,x2),dim=1)\n",
    "        #x = self.dp(x)\n",
    "        #x = self.bn(x)\n",
    "        \n",
    "\n",
    "        # use every word in the sentence\n",
    "        #x = x.contiguous().view(-1, x.size(1) * x.size(2))\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc1(x.float())\n",
    "        x = self.relu2(x)\n",
    "        x = self.dp(x)\n",
    "        x = self.fc2(x)\n",
    "        x = x / torch.norm(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(nb_words,\n",
    "        EMBEDDING_DIM,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=MAX_SEQUENCE_LENGTH,\n",
    "        trainable=False)\n",
    "lstm_layer = LSTM(num_lstm, dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm)\n",
    "\n",
    "sequence_1_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences_1 = embedding_layer(sequence_1_input)\n",
    "x1 = lstm_layer(embedded_sequences_1)\n",
    "\n",
    "sequence_2_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences_2 = embedding_layer(sequence_2_input)\n",
    "y1 = lstm_layer(embedded_sequences_2)\n",
    "\n",
    "merged = concatenate([x1, y1])\n",
    "merged = Dropout(rate_drop_dense)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "\n",
    "merged = Dense(num_dense, activation=act)(merged)\n",
    "merged = Dropout(rate_drop_dense)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "\n",
    "preds = Dense(1, activation='sigmoid')(merged)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
