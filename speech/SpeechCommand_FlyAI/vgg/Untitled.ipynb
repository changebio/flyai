{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from flyai.processor.base import Base\n",
    "from tensorflow.contrib.framework.python.ops import audio_ops as contrib_audio\n",
    "from tensorflow.python.ops import io_ops\n",
    "\n",
    "#import create_dict\n",
    "import model\n",
    "from path import DATA_PATH  # 导入输入数据的地址"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "from time import time\n",
    "import json\n",
    "import os\n",
    "import platform\n",
    "import random\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from flyai.processor.base import Base\n",
    "from flyai.processor.download import check_download\n",
    "from flyai.utils.yaml_helper import Yaml\n",
    "from flyai.utils import read_data\n",
    "\n",
    "from path import DATA_PATH\n",
    "\n",
    "import librosa\n",
    "import scipy.io.wavfile as wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Csv(config,line=\"\"):\n",
    "    if line is \"\":\n",
    "        line = True\n",
    "    else:\n",
    "        line = False\n",
    "    train_path = check_download(config['train_url'], DATA_PATH, is_print=line)\n",
    "    data = read_data.read(train_path)\n",
    "    val_path = check_download(config['test_url'], DATA_PATH, is_print=line)\n",
    "    val = read_data.read(val_path)\n",
    "    return data,val\n",
    "\n",
    "def load_csv(custom_source=None):\n",
    "    yaml = Yaml()\n",
    "    try:\n",
    "        f = open(os.path.join(sys.path[0], 'train.json'))\n",
    "        line = f.readline().strip()\n",
    "    except IOError:\n",
    "        line = \"\"\n",
    "\n",
    "    postdata = {'id': yaml.get_data_id(),\n",
    "                'env': line,\n",
    "                'time': time(),\n",
    "                'sign': random.random(),\n",
    "                'goos': platform.platform()}\n",
    "\n",
    "    try:\n",
    "        servers = yaml.get_servers()\n",
    "        r = requests.post(servers[0]['url'] + \"/dataset\", data=postdata)\n",
    "        source = json.loads(r.text)\n",
    "    except:\n",
    "        source = None\n",
    "\n",
    "    if source is None:\n",
    "        trn,val = Csv({'train_url': os.path.join(DATA_PATH, \"dev.csv\"),'test_url': os.path.join(DATA_PATH, \"dev.csv\")}, line)\n",
    "    elif 'yaml' in source:\n",
    "        source = source['yaml']\n",
    "        if custom_source is None:\n",
    "            trn,val = Csv(source['config'], line)\n",
    "        else:\n",
    "            source = custom_source\n",
    "    else:\n",
    "        if not os.path.exists(os.path.join(DATA_PATH, \"train.csv\")) and not os.path.exists(\n",
    "                os.path.join(DATA_PATH, \"test.csv\")):\n",
    "            raise Exception(\"invalid data id!\")\n",
    "        else:\n",
    "            trn,val = Csv({'train_url': os.path.join(DATA_PATH, \"train.csv\"),'test_url': os.path.join(DATA_PATH, \"test.csv\")}, line)\n",
    "    print(source)\n",
    "    return trn,val\n",
    "\n",
    "\n",
    "def load_data(combine=True,summary=True):\n",
    "    trn,val = load_csv()\n",
    "    if combine:\n",
    "        trn = pd.concat([trn,val])\n",
    "    if summary:\n",
    "        data_summary = trn.describe()\n",
    "        for k in range(data_summary.shape[1]):\n",
    "            print(list(data_summary.iloc[:,k]))\n",
    "        for i in range(1,trn.shape[1]):\n",
    "            print(trn.iloc[:,i].value_counts()[:10])\n",
    "    return trn, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'SpeechCommand', 'type': 'csv', 'config': {'train_url': 'https://dataset.flyai.com/dataset/SpeechCommand/dev.zip', 'test_url': 'https://dataset.flyai.com/dataset/SpeechCommand/dev.zip'}}\n",
      "[200, 100, 'audio/c5344cab965939d8f11ece248678eff6.wav', 2]\n",
      "[200, 12, 'go', 24]\n",
      "go         24\n",
      "off        20\n",
      "unknown    20\n",
      "no         20\n",
      "down       20\n",
      "left       20\n",
      "stop       20\n",
      "on         14\n",
      "right      12\n",
      "up         12\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "trn,val = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>audio/8ce19853dcf57ebd430abffb6efe529d.wav</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>audio/dd855dfa20b1a85b1fff4a90b5cc7438.wav</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>audio/601d7b92c411511ccf21f5fe2443c787.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>audio/064490b507249f6d0d8fc8cf8d43076d.wav</td>\n",
       "      <td>off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>audio/55e7f0e01b30de422f516b8ade928ddb.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>audio/33d690fcc67cbe934a36e7f3e0020915.wav</td>\n",
       "      <td>off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>audio/cc669b09c5800e09a31a48306a173841.wav</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>audio/939fc1c580534498b073c8514116b109.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>audio/b30f409423ac83f4c0f265715590d0fc.wav</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>audio/e56f1a4e2080f349f4ccbc129ae6dbb4.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>audio/6fce01b83587d6809e2290c6a3d01f55.wav</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>audio/02fdedd6caf5f9cc6d6a42ac38568649.wav</td>\n",
       "      <td>off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>audio/37675dd8cc091ccaac511bc28e9b5b36.wav</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>audio/fc7e2506980cecc700c0c83c54715c06.wav</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>audio/40c66a3227deaa785d717934a6256e16.wav</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>audio/fdd7eb4d16b45bb02bf2f2749674cd89.wav</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>audio/1d93382eb53cfdc95b896c0804bc8b87.wav</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>audio/e508206a673999e0e738fdc5c8322d1b.wav</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>audio/bc293e50eadd8f218a0c4c71ea159c78.wav</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>audio/771e07fdeee89ea4490e061e4aece523.wav</td>\n",
       "      <td>off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>audio/e74231eb13404dfcc0cfd8997abe4e0d.wav</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>audio/89ce5ef77c7725fce144cd6b5cd577c2.wav</td>\n",
       "      <td>off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>audio/60467c80f39b786e714e6f5ef1daceb4.wav</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>audio/5a25d68c4fd481296ec9a089393c7197.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>audio/6be25df841b85463d071780c10e958c5.wav</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>audio/5a5530b9992ef57cdc95080ad8656d48.wav</td>\n",
       "      <td>stop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>audio/fe8a258f98809f7bb7b3697f18913924.wav</td>\n",
       "      <td>stop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>audio/8a0f0950463b08551b22f0fc940504ed.wav</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>audio/446d36a94e89e58ecced395b0097dcfa.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>audio/29b8fc90b11ad53034d4ac677c8df2c3.wav</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>audio/2ecd81cfbf90d4d9974d430607450c76.wav</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>audio/61ede77fb566bd0afa4fa29736ffe6ae.wav</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>audio/37cbe9f95544aa9ea055561283a0264c.wav</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>audio/21f9d362a90cacdefa6dcc61df82c1b4.wav</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>audio/a5717e2c552dc87b42c2b34304d9bb07.wav</td>\n",
       "      <td>off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>audio/86d8c3463049e9cb54aaf8531ee75d5e.wav</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>audio/8382be6f01b9a6eea0061ca94cde9299.wav</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>audio/57809a727bb25dfc2056b8e7f7bbb0dc.wav</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>audio/09606723a09ce052d99a1cdccca2573e.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>audio/5feed37bf0f6cb9a73347121eea06d66.wav</td>\n",
       "      <td>stop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>audio/535e5aaf270ed785a900f91cd7393617.wav</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>audio/3fc9789e9ee8ac0c091500e34679ac9c.wav</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>audio/c50da9306976548bf359b58b77ae47e2.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>audio/582b25e1fd5e9bf2481f7bea3fb25d9b.wav</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>audio/1745fe5c14b1f8f84e14b7a0dbc189e7.wav</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>audio/8bd36a21ec22783de2a074b528b53305.wav</td>\n",
       "      <td>stop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>audio/2b3b726ab306ad0be4e5a3aea33ea949.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>audio/61b51937fe45534c4d1579dba7a18758.wav</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>audio/e2616194716945356348511d0a839137.wav</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>audio/a6195edb1ccb9fb6a4a34ff5abf2f393.wav</td>\n",
       "      <td>stop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>audio/7c5ef6f339a6636de40810781c69c229.wav</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>audio/f69dc6d2eda06a2fd7cf4160a8a2e82b.wav</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>audio/c1b28c164b2af44f9bba1bb00bb9193f.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>audio/3b4688cd3dd2cde296bd5b8642d4e1b5.wav</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>audio/205889ec09b2a596262ab20ce4407a9f.wav</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>audio/e5bc2bfe148b4c78812e37c312899abc.wav</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>audio/ad4214f50268679d24ef5233c0a367d9.wav</td>\n",
       "      <td>off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>audio/2d45ddbdb60d38c322727b5026a04a08.wav</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>audio/6e2e10898b7bd9f4f1e6d31622569318.wav</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>audio/11b209d720f9a8378ee8261d3d731357.wav</td>\n",
       "      <td>stop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           wav    label\n",
       "0   audio/8ce19853dcf57ebd430abffb6efe529d.wav       up\n",
       "1   audio/dd855dfa20b1a85b1fff4a90b5cc7438.wav       no\n",
       "2   audio/601d7b92c411511ccf21f5fe2443c787.wav  silence\n",
       "3   audio/064490b507249f6d0d8fc8cf8d43076d.wav      off\n",
       "4   audio/55e7f0e01b30de422f516b8ade928ddb.wav  unknown\n",
       "5   audio/33d690fcc67cbe934a36e7f3e0020915.wav      off\n",
       "6   audio/cc669b09c5800e09a31a48306a173841.wav       on\n",
       "7   audio/939fc1c580534498b073c8514116b109.wav  silence\n",
       "8   audio/b30f409423ac83f4c0f265715590d0fc.wav     down\n",
       "9   audio/e56f1a4e2080f349f4ccbc129ae6dbb4.wav  unknown\n",
       "10  audio/6fce01b83587d6809e2290c6a3d01f55.wav    right\n",
       "11  audio/02fdedd6caf5f9cc6d6a42ac38568649.wav      off\n",
       "12  audio/37675dd8cc091ccaac511bc28e9b5b36.wav     down\n",
       "13  audio/fc7e2506980cecc700c0c83c54715c06.wav       no\n",
       "14  audio/40c66a3227deaa785d717934a6256e16.wav    right\n",
       "15  audio/fdd7eb4d16b45bb02bf2f2749674cd89.wav     down\n",
       "16  audio/1d93382eb53cfdc95b896c0804bc8b87.wav       no\n",
       "17  audio/e508206a673999e0e738fdc5c8322d1b.wav     left\n",
       "18  audio/bc293e50eadd8f218a0c4c71ea159c78.wav       on\n",
       "19  audio/771e07fdeee89ea4490e061e4aece523.wav      off\n",
       "20  audio/e74231eb13404dfcc0cfd8997abe4e0d.wav       go\n",
       "21  audio/89ce5ef77c7725fce144cd6b5cd577c2.wav      off\n",
       "22  audio/60467c80f39b786e714e6f5ef1daceb4.wav       no\n",
       "23  audio/5a25d68c4fd481296ec9a089393c7197.wav  unknown\n",
       "24  audio/6be25df841b85463d071780c10e958c5.wav       go\n",
       "25  audio/5a5530b9992ef57cdc95080ad8656d48.wav     stop\n",
       "26  audio/fe8a258f98809f7bb7b3697f18913924.wav     stop\n",
       "27  audio/8a0f0950463b08551b22f0fc940504ed.wav       go\n",
       "28  audio/446d36a94e89e58ecced395b0097dcfa.wav  unknown\n",
       "29  audio/29b8fc90b11ad53034d4ac677c8df2c3.wav       go\n",
       "..                                         ...      ...\n",
       "70  audio/2ecd81cfbf90d4d9974d430607450c76.wav       no\n",
       "71  audio/61ede77fb566bd0afa4fa29736ffe6ae.wav     down\n",
       "72  audio/37cbe9f95544aa9ea055561283a0264c.wav       no\n",
       "73  audio/21f9d362a90cacdefa6dcc61df82c1b4.wav     down\n",
       "74  audio/a5717e2c552dc87b42c2b34304d9bb07.wav      off\n",
       "75  audio/86d8c3463049e9cb54aaf8531ee75d5e.wav       up\n",
       "76  audio/8382be6f01b9a6eea0061ca94cde9299.wav       up\n",
       "77  audio/57809a727bb25dfc2056b8e7f7bbb0dc.wav       go\n",
       "78  audio/09606723a09ce052d99a1cdccca2573e.wav  silence\n",
       "79  audio/5feed37bf0f6cb9a73347121eea06d66.wav     stop\n",
       "80  audio/535e5aaf270ed785a900f91cd7393617.wav       go\n",
       "81  audio/3fc9789e9ee8ac0c091500e34679ac9c.wav       on\n",
       "82  audio/c50da9306976548bf359b58b77ae47e2.wav  unknown\n",
       "83  audio/582b25e1fd5e9bf2481f7bea3fb25d9b.wav      yes\n",
       "84  audio/1745fe5c14b1f8f84e14b7a0dbc189e7.wav       go\n",
       "85  audio/8bd36a21ec22783de2a074b528b53305.wav     stop\n",
       "86  audio/2b3b726ab306ad0be4e5a3aea33ea949.wav  unknown\n",
       "87  audio/61b51937fe45534c4d1579dba7a18758.wav       no\n",
       "88  audio/e2616194716945356348511d0a839137.wav      yes\n",
       "89  audio/a6195edb1ccb9fb6a4a34ff5abf2f393.wav     stop\n",
       "90  audio/7c5ef6f339a6636de40810781c69c229.wav    right\n",
       "91  audio/f69dc6d2eda06a2fd7cf4160a8a2e82b.wav     down\n",
       "92  audio/c1b28c164b2af44f9bba1bb00bb9193f.wav  silence\n",
       "93  audio/3b4688cd3dd2cde296bd5b8642d4e1b5.wav       up\n",
       "94  audio/205889ec09b2a596262ab20ce4407a9f.wav       go\n",
       "95  audio/e5bc2bfe148b4c78812e37c312899abc.wav    right\n",
       "96  audio/ad4214f50268679d24ef5233c0a367d9.wav      off\n",
       "97  audio/2d45ddbdb60d38c322727b5026a04a08.wav     down\n",
       "98  audio/6e2e10898b7bd9f4f1e6d31622569318.wav    right\n",
       "99  audio/11b209d720f9a8378ee8261d3d731357.wav     stop\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioProcessor(object):\n",
    "\n",
    "    def prepare_processing_graph(self, model_settings):\n",
    "        \"\"\"Builds a TensorFlow graph to apply the input distortions.\n",
    "\n",
    "        Creates a graph that loads a WAVE file, decodes it, scales the volume,\n",
    "        shifts it in time, adds in background noise, calculates a spectrogram, and\n",
    "        then builds an MFCC fingerprint from that.\n",
    "\n",
    "        This must be called with an active TensorFlow session running, and it\n",
    "        creates multiple placeholder inputs, and one output:\n",
    "\n",
    "          - wav_filename_placeholder_: Filename of the WAV to load.\n",
    "          - foreground_volume_placeholder_: How loud the main clip should be.\n",
    "          - time_shift_padding_placeholder_: Where to pad the clip.\n",
    "          - time_shift_offset_placeholder_: How much to move the clip in time.\n",
    "          - background_data_placeholder_: PCM sample data for background noise.\n",
    "          - background_volume_placeholder_: Loudness of mixed-in background.\n",
    "          - mfcc_: Output 2D fingerprint of processed audio.\n",
    "\n",
    "        Args:\n",
    "          model_settings: Information about the current model being trained.\n",
    "        \"\"\"\n",
    "        desired_samples = model_settings['desired_samples']\n",
    "        self.wav_filename_placeholder_ = tf.placeholder(tf.string, [])\n",
    "        wav_loader = io_ops.read_file(self.wav_filename_placeholder_)\n",
    "        wav_decoder = contrib_audio.decode_wav(\n",
    "            wav_loader, desired_channels=1, desired_samples=desired_samples)\n",
    "        # Allow the audio sample's volume to be adjusted.\n",
    "        self.foreground_volume_placeholder_ = tf.placeholder(tf.float32, [])\n",
    "        scaled_foreground = tf.multiply(wav_decoder.audio,\n",
    "                                        self.foreground_volume_placeholder_)\n",
    "        # Shift the sample's start position, and pad any gaps with zeros.\n",
    "        self.time_shift_padding_placeholder_ = tf.placeholder(tf.int32, [2, 2])\n",
    "        self.time_shift_offset_placeholder_ = tf.placeholder(tf.int32, [2])\n",
    "        padded_foreground = tf.pad(\n",
    "            scaled_foreground,\n",
    "            self.time_shift_padding_placeholder_,\n",
    "            mode='CONSTANT')\n",
    "        sliced_foreground = tf.slice(padded_foreground,\n",
    "                                     self.time_shift_offset_placeholder_,\n",
    "                                     [desired_samples, -1])\n",
    "        # Mix in background noise.\n",
    "        self.background_data_placeholder_ = tf.placeholder(tf.float32,\n",
    "                                                           [desired_samples, 1])\n",
    "        self.background_volume_placeholder_ = tf.placeholder(tf.float32, [])\n",
    "        background_mul = tf.multiply(self.background_data_placeholder_,\n",
    "                                     self.background_volume_placeholder_)\n",
    "        background_add = tf.add(background_mul, sliced_foreground)\n",
    "        background_clamp = tf.clip_by_value(background_add, -1.0, 1.0)\n",
    "        # Run the spectrogram and MFCC ops to get a 2D 'fingerprint' of the audio.\n",
    "        spectrogram = contrib_audio.audio_spectrogram(\n",
    "            background_clamp,\n",
    "            window_size=model_settings['window_size_samples'],\n",
    "            stride=model_settings['window_stride_samples'],\n",
    "            magnitude_squared=True)\n",
    "        self.mfcc_ = contrib_audio.mfcc(\n",
    "            spectrogram,\n",
    "            wav_decoder.sample_rate,\n",
    "            dct_coefficient_count=model_settings['dct_coefficient_count'])\n",
    "\n",
    "    def get_data(self, filename, model_settings, time_shift, sess):\n",
    "        \"\"\"Gather samples from the data set, applying transformations as needed.\n",
    "\n",
    "        When the mode is 'training', a random selection of samples will be returned,\n",
    "        otherwise the first N clips in the partition will be used. This ensures that\n",
    "        validation always uses the same samples, reducing noise in the metrics.\n",
    "\n",
    "        Args:\n",
    "          model_settings: Information about the current model being trained.\n",
    "          background_frequency: How many clips will have background noise, 0.0 to\n",
    "            1.0.\n",
    "          background_volume_range: How loud the background noise will be.\n",
    "          time_shift: How much to randomly shift the clips by in time.\n",
    "          mode: Which partition to use, must be 'training', 'validation', or\n",
    "            'testing'.\n",
    "          sess: TensorFlow session that was active when processor was created.\n",
    "\n",
    "        Returns:\n",
    "          List of sample data for the transformed samples, and list of labels in\n",
    "          one-hot form.\n",
    "        \"\"\"\n",
    "        sample_count = 1\n",
    "        data = np.zeros((sample_count, model_settings['fingerprint_size']))\n",
    "        desired_samples = model_settings['desired_samples']\n",
    "        # If we're time shifting, set up the offset for this sample.\n",
    "        if time_shift > 0:\n",
    "            time_shift_amount = np.random.randint(-time_shift, time_shift)\n",
    "        else:\n",
    "            time_shift_amount = 0\n",
    "        if time_shift_amount > 0:\n",
    "            time_shift_padding = [[time_shift_amount, 0], [0, 0]]\n",
    "            time_shift_offset = [0, 0]\n",
    "        else:\n",
    "            time_shift_padding = [[0, -time_shift_amount], [0, 0]]\n",
    "            time_shift_offset = [-time_shift_amount, 0]\n",
    "        input_dict = {\n",
    "            self.wav_filename_placeholder_: filename,\n",
    "            self.time_shift_padding_placeholder_: time_shift_padding,\n",
    "            self.time_shift_offset_placeholder_: time_shift_offset,\n",
    "        }\n",
    "        background_reshaped = np.zeros([desired_samples, 1])\n",
    "        background_volume = 0\n",
    "        input_dict[self.background_data_placeholder_] = background_reshaped\n",
    "        input_dict[self.background_volume_placeholder_] = background_volume\n",
    "        input_dict[self.foreground_volume_placeholder_] = 1\n",
    "        # Run the graph to produce the output audio.\n",
    "        tmp = sess.run(self.mfcc_, feed_dict=input_dict).flatten()\n",
    "        data[0, :] = tmp\n",
    "        return data\n",
    "\n",
    "    def get_unprocessed_data(self, filename, model_settings):\n",
    "        \"\"\"Retrieve sample data for the given partition, with no transformations.\n",
    "\n",
    "        Args:\n",
    "          how_many: Desired number of samples to return. -1 means the entire\n",
    "            contents of this partition.\n",
    "          model_settings: Information about the current model being trained.\n",
    "          mode: Which partition to use, must be 'training', 'validation', or\n",
    "            'testing'.\n",
    "\n",
    "        Returns:\n",
    "          List of sample data for the samples, and list of labels in one-hot form.\n",
    "        \"\"\"\n",
    "        desired_samples = model_settings['desired_samples']\n",
    "        data = np.zeros((1, desired_samples))\n",
    "        with tf.Session(graph=tf.Graph()) as sess:\n",
    "            wav_filename_placeholder = tf.placeholder(tf.string, [])\n",
    "            wav_loader = io_ops.read_file(wav_filename_placeholder)\n",
    "            wav_decoder = contrib_audio.decode_wav(\n",
    "                wav_loader, desired_channels=1, desired_samples=desired_samples)\n",
    "            foreground_volume_placeholder = tf.placeholder(tf.float32, [])\n",
    "            scaled_foreground = tf.multiply(wav_decoder.audio,\n",
    "                                            foreground_volume_placeholder)\n",
    "            input_dict = {wav_filename_placeholder: filename}\n",
    "            input_dict[foreground_volume_placeholder] = 1\n",
    "            data[0, :] = sess.run(scaled_foreground, feed_dict=input_dict).flatten()\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_processor = AudioProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TENSORFLOW_MODEL_DIR = \"best\"\n",
    "\n",
    "time_shift_ms = 100.0\n",
    "sample_rate = 16000\n",
    "clip_duration_ms = 1000\n",
    "window_size_ms = 30.0\n",
    "window_stride_ms = 10.0\n",
    "dct_coefficient_count = 40\n",
    "label_count = 12\n",
    "\n",
    "\n",
    "def prepare_model_settings():\n",
    "    \"\"\"Calculates common settings needed for all models.\n",
    "\n",
    "    Args:\n",
    "      label_count: How many classes are to be recognized.\n",
    "      sample_rate: Number of audio samples per second.\n",
    "      clip_duration_ms: Length of each audio clip to be analyzed.\n",
    "      window_size_ms: Duration of frequency analysis window.\n",
    "      window_stride_ms: How far to move in time between frequency windows.\n",
    "      dct_coefficient_count: Number of frequency bins to use for analysis.\n",
    "\n",
    "    Returns:\n",
    "      Dictionary containing common settings.\n",
    "    \"\"\"\n",
    "    desired_samples = int(sample_rate * clip_duration_ms / 1000)\n",
    "    window_size_samples = int(sample_rate * window_size_ms / 1000)\n",
    "    window_stride_samples = int(sample_rate * window_stride_ms / 1000)\n",
    "    length_minus_window = (desired_samples - window_size_samples)\n",
    "    if length_minus_window < 0:\n",
    "        spectrogram_length = 0\n",
    "    else:\n",
    "        spectrogram_length = 1 + int(length_minus_window / window_stride_samples)\n",
    "    fingerprint_size = dct_coefficient_count * spectrogram_length\n",
    "    return {\n",
    "        'desired_samples': desired_samples,\n",
    "        'window_size_samples': window_size_samples,\n",
    "        'window_stride_samples': window_stride_samples,\n",
    "        'spectrogram_length': spectrogram_length,\n",
    "        'dct_coefficient_count': dct_coefficient_count,\n",
    "        'fingerprint_size': fingerprint_size,\n",
    "        'label_count': label_count,\n",
    "        'sample_rate': sample_rate,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_settings = prepare_model_settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_processor.prepare_processing_graph(model_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.1\n",
    "with tf.Session(config=config) as sess:\n",
    "    data = audio_processor.get_data(os.path.join(DATA_PATH, 'audio/8ce19853dcf57ebd430abffb6efe529d.wav'), model_settings, 0, sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-25.09768295,   4.66023445,   1.74488676, ...,   0.38340071,\n",
       "         -0.05255827,   0.08426275]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3920)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Processor(Base):\n",
    "    def __init__(self):\n",
    "        super(Processor, self).__init__()\n",
    "        self.audio_processor = AudioProcessor()\n",
    "        self.model_settings = model.prepare_model_settings()\n",
    "        self.audio_processor.prepare_processing_graph(self.model_settings)\n",
    "        self.label_dict, self.label_dict_res = create_dict.load_label_dict()\n",
    "\n",
    "    def input_x(self, wav):\n",
    "        '''\n",
    "        参数为csv中作为输入x的一条数据，该方法会被Dataset多次调用\n",
    "        '''\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        config.gpu_options.per_process_gpu_memory_fraction = 0.1\n",
    "        with tf.Session(config=config) as sess:\n",
    "            data = self.audio_processor.get_data(os.path.join(DATA_PATH, wav), self.model_settings, 0, sess)\n",
    "        return np.squeeze(data, axis=0)\n",
    "\n",
    "    def input_y(self, label):\n",
    "        '''\n",
    "        参数为csv中作为输入y的一条数据，该方法会被Dataset多次调用\n",
    "        '''\n",
    "        label_count = self.model_settings['label_count']\n",
    "        y = np.zeros((label_count,))\n",
    "        if label in self.label_dict:\n",
    "            y[self.label_dict[label]] = 1\n",
    "        else:\n",
    "            y[1] = 1\n",
    "        return y\n",
    "\n",
    "    def output_y(self, data):\n",
    "        '''\n",
    "        验证时使用，把模型输出的y转为对应的结果\n",
    "        '''\n",
    "        out_y = np.argmax(data)\n",
    "        if out_y in self.label_dict_res:\n",
    "            return self.label_dict_res[out_y]\n",
    "        else:\n",
    "            return self.label_dict_res[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
